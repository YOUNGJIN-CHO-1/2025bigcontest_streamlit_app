import os
import sys
import json
import time
import shutil
import asyncio
import base64
import streamlit as st
import google.generativeai as genai
import pandas as pd
import re, difflib

from typing import Any, Dict, List
from pathlib import Path
from PIL import Image

from mcp.client.stdio import stdio_client
from mcp import ClientSession, StdioServerParameters
from langchain_mcp_adapters.tools import load_mcp_tools
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage

# ---------------------------
# í™˜ê²½ì„¤ì •: Google API Key
# ---------------------------
# GOOGLE_API_KEY = (
#     st.secrets.get("GOOGLE_API_KEY") if "GOOGLE_API_KEY" in st.secrets
#     else os.environ.get("GOOGLE_API_KEY")
# )
# if not GOOGLE_API_KEY:
#     st.warning("âš ï¸ GOOGLE_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. st.secrets ë˜ëŠ” í™˜ê²½ë³€ìˆ˜ë¥¼ ì„¤ì •í•˜ì„¸ìš”.")
# genai.configure(api_key=GOOGLE_API_KEY)

GOOGLE_API_KEY = "AIzaSyB8R3nurDOohfAvKXSgBUVRkoliXtfnTKo"
genai.configure(api_key=GOOGLE_API_KEY)

# ---------------------------
# LLM (Gemini) í—¬í¼
# ---------------------------
def call_gemini_json(system_prompt: str, user_payload: str) -> Dict[str, Any]:
    model = genai.GenerativeModel("gemini-2.5-flash")
    time.sleep(0.2)
    resp = model.generate_content(
        f"{system_prompt}\n\n{user_payload}",
        generation_config={"response_mime_type": "application/json"},
    )
    try:
        return json.loads(resp.text)
    except Exception as e:
        return {"error": f"JSON íŒŒì‹± ì‹¤íŒ¨: {e}", "raw": resp.text}

# ---------------------------
# ì—ì´ì „íŠ¸(ì¶”ë¡ /ë¦¬í¬íŒ…) ë¡œì§
# ---------------------------
class InteractiveParallelAgent:
    # 1) ë³€í™˜
    _TRANSFORM_SYSTEM_PROMPT = """
ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ ìì—°ì–´ ìš”ì²­ì„ êµ¬ì¡°í™”ëœ ë°ì´í„°ë¡œ ë³€í™˜í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì‚¬ìš©ìì˜ ìš”ì²­ì„ ë¶„ì„í•˜ì—¬ ë‹¤ìŒ ë„¤ ê°€ì§€ JSON í•­ëª©ìœ¼ë¡œ ìš”ì•½í•˜ì„¸ìš”.
- "target": ì‚¬ìš©ìê°€ ì „ëµì„ ìš”ì²­í•œ ê°€ë§¹ì ëª…ê³¼ ì—…ì¢…ì€ ë¬´ì—‡ì¸ê°€ìš”? (ê°€ë§¹ì  ì´ë¦„. ì˜ˆ: 'ì„±ìš°**')
- "challenge": ì‚¬ìš©ìê°€ ì§ë©´í•œ ì–´ë ¤ì›€ì´ë‚˜ í•´ê²°í•´ì•¼ í•  í•µì‹¬ ë¬¸ì œëŠ” ë¬´ì—‡ì¸ê°€ìš”?
- "objective": ëª©í‘œ ë‹¬ì„±ì„ ìœ„í•œ êµ¬ì²´ì ì¸ ëª©í‘œì€ ë¬´ì—‡ì¸ê°€ìš”?
- "solution_direction": ì œì•ˆë  ìˆ˜ ìˆëŠ” í•´ê²°ì±…ì˜ ë°©í–¥ì€ ë¬´ì—‡ì¸ê°€ìš”?
"""

    # 3) ë¬¸ì œ ì •ì˜
    _DEFINE_PROBLEM_SYSTEM_PROMPT = """
ë‹¹ì‹ ì€ ë°ì´í„° ë¶„ì„ê°€ì…ë‹ˆë‹¤. ì œê³µëœ ê°€ë§¹ì ì˜ ì‹œê³„ì—´ ë°ì´í„°ì™€ ìµœì´ˆ ì‚¬ìš©ì ìš”ì²­ì„ ê¸°ë°˜ìœ¼ë¡œ, ë¬¸ì œ ìƒí™©ê³¼ í•µì‹¬ ì„±ê³¼ ì§€í‘œ(KPI)ë¥¼ êµ¬ì²´ì ìœ¼ë¡œ ì •ì˜í•˜ì„¸ìš”.
íŠ¹íˆ, ì‹œê°„ì˜ íë¦„ì— ë”°ë¥¸ ë°ì´í„°ì˜ ë³€í™”ì™€ ì¶”ì„¸ë¥¼ ëª…í™•í•˜ê²Œ íŒŒì•…í•˜ê³ , ì´ë¥¼ ë¬¸ì œ ì •ì˜ì— ë°˜ì˜í•˜ì„¸ìš”.
ê²°ê³¼ JSON:
- "problem_statement": ì‹œê³„ì—´ ë³€í™”ì— ê¸°ë°˜í•œ ë¬¸ì œ ì •ì˜
- "kpis": ì¸¡ì • ê°€ëŠ¥í•œ í•µì‹¬ ì§€í‘œ ëª©ë¡(ë¬¸ìì—´ ë°°ì—´)
"""

    # 4) ì „ëµ ì œì•ˆ
    _PROPOSE_STRATEGY_SYSTEM_PROMPT = """
ë‹¹ì‹ ì€ ë¹„ì¦ˆë‹ˆìŠ¤ ì „ëµ ì»¨ì„¤í„´íŠ¸ì…ë‹ˆë‹¤.
ë¬¸ì œ ì •ì˜ë¥¼ ê¸°ë°˜ìœ¼ë¡œ êµ¬ì²´ì ì´ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ ì „ëµì„ ì œì•ˆí•˜ì„¸ìš”.
ì‹œê³„ì—´ì—ì„œ ê°ì§€ëœ ì¶”ì„¸ë¥¼ ë°˜ì „/ê°•í™”í•˜ëŠ” ë°©í–¥ìœ¼ë¡œ ì„¤ê³„í•˜ì„¸ìš”.
ê²°ê³¼ JSON:
- "problem_definition": í•µì‹¬ ë¬¸ì œ ìš”ì•½
- "proposed_strategy": ì‹¤í–‰ ë°©ì•ˆ ëª©ë¡
- "strategic_rationale": ì™œ ì´ê²ƒì´ íš¨ê³¼ì ì¸ì§€ (ë°ì´í„° ì¶”ì„¸ì™€ ì—°ê²°)
"""

    # 5) ë³´ê³ ì„œ ì‘ì„±
    _GENERATE_REPORT_SYSTEM_PROMPT = """
ë‹¹ì‹ ì€ ì „ë¬¸ ë³´ê³ ì„œ ì‘ì„±ìì…ë‹ˆë‹¤.
ì§€ê¸ˆê¹Œì§€ì˜ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì¢…í•©í•˜ì—¬, ì„œë¡ (ë¬¸ì œ ë°°ê²½) - ë³¸ë¡ (ì‹œê³„ì—´ ë¶„ì„/ë¬¸ì œì •ì˜/ì „ëµ) - ê²°ë¡ (ê¸°ëŒ€íš¨ê³¼) êµ¬ì¡°ì˜ ë§ˆí¬ë‹¤ìš´ ë³´ê³ ì„œë¥¼ ìƒì„±í•˜ì„¸ìš”.
ìµœì¢… ì¶œë ¥ì€ {"report": "<markdown>"} JSON í•œ ê°œ í‚¤ë§Œ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤.
"""

    def __init__(self):
        self.context: Dict[str, Any] = {}

    def transform(self, initial_input: str):
        user = f"ğŸ”¹ ì‚¬ìš©ì ì…ë ¥: {initial_input}"
        self.context["transformation"] = call_gemini_json(
            self._TRANSFORM_SYSTEM_PROMPT, user
        )
        return self.context["transformation"]

    def define_problem(self, exploration: Dict[str, Any], transformation: Dict[str, Any]):
        user = "ğŸ”¹ ë¬¸ë§¥:\n" + json.dumps(
            {"ìµœì´ˆìš”ì²­": transformation, "ì‹œê³„ì—´": exploration}, ensure_ascii=False, indent=2
        )
        self.context["problem_definition"] = call_gemini_json(
            self._DEFINE_PROBLEM_SYSTEM_PROMPT, user
        )
        return self.context["problem_definition"]

    def propose_strategy(self, problem_definition: Dict[str, Any]):
        user = "ğŸ”¹ ë¬¸ë§¥:\n" + json.dumps(
            {"ë¬¸ì œì •ì˜": problem_definition}, ensure_ascii=False, indent=2
        )
        self.context["strategy"] = call_gemini_json(
            self._PROPOSE_STRATEGY_SYSTEM_PROMPT, user
        )
        return self.context["strategy"]
    
    # â¬‡ï¸ InteractiveParallelAgent ì•ˆì— ìœ í‹¸ í•˜ë‚˜ ì¶”ê°€
    def _compact_context(self, full_ctx: Dict[str, Any], max_rows: int = 12) -> Dict[str, Any]:
        """LLMì— ë„˜ê¸¸ ì»¨í…ìŠ¤íŠ¸ë¥¼ ìŠ¬ë¦¼í™”: ìµœê·¼ Nê°œì›”ë§Œ í¬í•¨"""
        slim = {}
        # 1) ë³€í™˜/ë¬¸ì œì •ì˜/ì „ëµë§Œ ìœ ì§€
        for k in ("transformation", "problem_definition", "strategy"):
            if k in full_ctx:
                slim[k] = full_ctx[k]
        # 2) ì‹œê³„ì—´ì€ ìµœê·¼ Nê°œì›”ë§Œ
        exp = full_ctx.get("exploration") or {}
        ts = (exp.get("time_series_analysis_data") or [])[-max_rows:]
        slim["exploration_summary"] = {
            "store_identity": exp.get("store_identity"),
            "time_series_tail": ts,
            "tail_note": f"ìµœê·¼ {min(max_rows, len(ts))}ê°œì›”ë§Œ í¬í•¨",
        }
        return slim

    def generate_report(self) -> str:
        user = "ğŸ”¹ ì „ì²´ ì»¨í…ìŠ¤íŠ¸:\n" + json.dumps(
            self.context, ensure_ascii=False, indent=2
        )
        out = call_gemini_json(self._GENERATE_REPORT_SYSTEM_PROMPT, user)
        return out.get("report", "ë³´ê³ ì„œ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")

    # â¬‡ï¸ generate_report() êµì²´
    def generate_report(self) -> str:
        # self.contextì— explorationì„ ë¯¸ë¦¬ ë„£ì–´ë‘ì—ˆë‹¤ëŠ” ì „ì œ(ì´ë¯¸ run_full_pipelineì—ì„œ ê·¸ë ‡ê²Œ ì‚¬ìš© ì¤‘)
        compact = self._compact_context(self.context, max_rows=12)

        user = "ğŸ”¹ ì „ì²´ ì»¨í…ìŠ¤íŠ¸(ìŠ¬ë¦¼):\n" + json.dumps(compact, ensure_ascii=False, indent=2)
        out = call_gemini_json(self._GENERATE_REPORT_SYSTEM_PROMPT, user)

        # 1ì°¨: ì •ìƒ í‚¤ ì‚¬ìš©
        if isinstance(out, dict) and out.get("report"):
            return out["report"]

        # 2ì°¨: ì‘ë‹µ ë³µêµ¬(ëª¨ë¸ì´ report í‚¤ë¥¼ ë†“ì¹œ ê²½ìš°)
        raw = out.get("raw") if isinstance(out, dict) else None
        if raw:
            # report í‚¤ë§Œ ê°•ì œ ë˜í•‘í•´ì„œ ì‚¬ìš©
            return raw if raw.strip().startswith("#") else f"# ìš”ì•½ ë³´ê³ ì„œ\n\n{raw}"

        return "ë³´ê³ ì„œ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."

# ---------------------------
# MCP í˜¸ì¶œ ìœ í‹¸ (í•„ìš” ì‹œë§ˆë‹¤ ì—°ê²°)
# ---------------------------
async def _mcp_call(tool_name: str, args: dict) -> dict:
    server_path = (Path(__file__).parent / "mcp_server_v3.py").resolve()
    if not server_path.exists():
        return {"error": f"MCP ì„œë²„ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {server_path}"}

    uv_path = shutil.which("uv")
    if uv_path:
        command = uv_path
        cmd_args = ["run", str(server_path)]
    else:
        command = sys.executable
        cmd_args = ["-u", str(server_path)]

    env = os.environ.copy()
    env.setdefault("PYTHONUNBUFFERED", "1")
    env.setdefault("PYTHONIOENCODING", "utf-8")

    server_params = StdioServerParameters(command=command, args=cmd_args, env=env)

    try:
        async with asyncio.timeout(20):
            async with stdio_client(server_params) as (read, write):
                async with ClientSession(read, write) as session:
                    await session.initialize()
                    tools = await load_mcp_tools(session)
                    tool_map = {t.name: t for t in tools}
                    if tool_name not in tool_map:
                        return {"error": f"íˆ´ '{tool_name}'ì„(ë¥¼) ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                                "available": list(tool_map.keys())}
                    result = await tool_map[tool_name].ainvoke(args)
                    if isinstance(result, str):
                        try:
                            return json.loads(result)
                        except Exception:
                            return {"raw": result}
                    return result
    except Exception as e:
        return {"error": f"MCP í˜¸ì¶œ ì¤‘ ì˜ˆì™¸: {e.__class__.__name__}: {e}"}

def mcp_call(tool_name: str, args: dict) -> dict:
    try:
        return asyncio.run(_mcp_call(tool_name, args))
    except RuntimeError:
        loop = asyncio.new_event_loop()
        try:
            return loop.run_until_complete(_mcp_call(tool_name, args))
        finally:
            loop.close()

# ---------------------------
# Streamlit UI
# ---------------------------
ASSETS = Path("assets")
st.set_page_config(page_title="2025ë…„ ë¹…ì½˜í…ŒìŠ¤íŠ¸ AIë°ì´í„° í™œìš©ë¶„ì•¼ - ë§›ì§‘ì„ ìˆ˜í˜¸í•˜ëŠ” AIë¹„ë°€ìƒë‹´ì‚¬", layout="wide")
st.title("ì‹ í•œì¹´ë“œ ì†Œìƒê³µì¸ ë¹„ë°€ìƒë‹´ì†Œ ğŸ”‘")

system_prompt = "ë‹¹ì‹ ì€ ì¹œì ˆí•œ ë§ˆì¼€íŒ… ìƒë‹´ì‚¬ì…ë‹ˆë‹¤. ê°€ë§¹ì ëª…ì„ ë°›ì•„ í•´ë‹¹ ê°€ë§¹ì ì˜ ë°©ë¬¸ ê³ ê° í˜„í™©ì„ ë¶„ì„í•˜ê³ , ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì ì ˆí•œ ë§ˆì¼€íŒ… ë°©ë²•ê³¼ ì±„ë„, ë§ˆì¼€íŒ… ë©”ì‹œì§€ë¥¼ ì¶”ì²œí•©ë‹ˆë‹¤. ê²°ê³¼ëŠ” ì§§ê³  ê°„ê²°í•˜ê²Œ, ë¶„ì„ ê²°ê³¼ì—ëŠ” ê°€ëŠ¥í•œ í‘œë¥¼ ì‚¬ìš©í•˜ì—¬ ì•Œì•„ë³´ê¸° ì‰½ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”."
greeting = "ë§ˆì¼€íŒ…ì´ í•„ìš”í•œ ê°€ë§¹ì ì„ ì•Œë ¤ì£¼ì„¸ìš”."

@st.cache_data
def load_image(name: str):
    return Image.open(ASSETS / name)

def clear_chat_history():
    # ì±„íŒ…/ìƒíƒœ ì „ë¶€ ì´ˆê¸°í™”
    st.session_state.messages = [
        SystemMessage(content=system_prompt),
        AIMessage(content=greeting),
    ]
    st.session_state.awaiting_candidate = False
    st.session_state.candidates = []
    st.session_state.exploration = None
    st.session_state.transformation = None
    st.session_state.selected_merchant_id = None
    st.session_state.last_chart_b64 = None
    st.session_state.user_query = ""

# í›„ë³´ í‘œì‹œ í¬ë§·
def _id_of(cand: dict):
    return cand.get("ê°€ë§¹ì êµ¬ë¶„ë²ˆí˜¸")

def _fmt_cand_with_id(c: dict) -> str:
    id_val = _id_of(c) or "UNKNOWN_ID"
    area = c.get("ìƒê¶Œ", None)
    area_txt = "(ìƒê¶Œ ì—†ìŒ)" if (area is None) else str(area)
    name = c.get("ê°€ë§¹ì ëª…", "?")
    industry = c.get("ì—…ì¢…", "?")
    return f"[{id_val}] {name} / {industry} / {area_txt}"

# ì„¸ì…˜ ìƒíƒœ
# --- session state ---
if "messages" not in st.session_state:
    st.session_state.messages: List[Any] = [
        SystemMessage(content=system_prompt),
        AIMessage(content=greeting),
    ]
if "agent" not in st.session_state:
    st.session_state.agent = InteractiveParallelAgent()
if "exploration" not in st.session_state:
    st.session_state.exploration = None
if "transformation" not in st.session_state:
    st.session_state.transformation = None
if "candidates" not in st.session_state:
    st.session_state.candidates: List[dict] = []
if "awaiting_candidate" not in st.session_state:
    st.session_state.awaiting_candidate = False   # í›„ë³´ ì„ íƒ ë‹¨ê³„ì¸ì§€
if "selected_merchant_id" not in st.session_state:
    st.session_state.selected_merchant_id = None
if "last_chart_b64" not in st.session_state:
    st.session_state.last_chart_b64 = None

with st.sidebar:
    if (ASSETS / "shc_ci_basic_00.png").exists():
        st.image(load_image("shc_ci_basic_00.png"), width="stretch")
    st.markdown("<p style='text-align: center;'>2025 Big Contest â€¢ AI DATA í™œìš©</p>", unsafe_allow_html=True)
    st.button("Clear Chat History", on_click=clear_chat_history)  # ë²„íŠ¼ ì¶”ê°€

    # ìµœê·¼ ìë™ ìƒì„±ëœ ì°¨íŠ¸
    if st.session_state.last_chart_b64:
        st.markdown("#### ìµœê·¼ KPI ì°¨íŠ¸")
        st.image(base64.b64decode(st.session_state.last_chart_b64), width="stretch")

def render_history():
    for msg in st.session_state.messages:
        if isinstance(msg, HumanMessage):
            with st.chat_message("user"):
                st.write(msg.content)
        elif isinstance(msg, AIMessage):
            with st.chat_message("assistant"):
                st.write(msg.content)
        elif isinstance(msg, SystemMessage):
            # ì‹œìŠ¤í…œ ë©”ì‹œì§€ëŠ” í™”ë©´ì—” ì•ˆ ë³´ì´ê²Œ í•˜ë ¤ë©´ ì£¼ì„
            pass

render_history()

def _normalize_kpi_name(name: str) -> str:
    """ê´„í˜¸ ë’¤ ì„¤ëª… ì œê±°, ê³µë°± ì •ë¦¬, ëŒ€í‘œ ì¹˜í™˜ ë“±."""
    if not name:
        return ""
    s = str(name).strip()
    # ë’¤ìª½ ê´„í˜¸ ì„¤ëª… ì œê±°: "KPIëª… (ì„¤ëª…)" â†’ "KPIëª…"
    s = re.sub(r"\s*\(.*?\)\s*$", "", s)
    # í”í•œ ë™ì˜ì–´/ì˜¤íƒ€ ì¹˜í™˜
    synonyms = {
        "ë™ì¼ ì—…ì¢… ë§¤ì¶œê¸ˆì•¡ ë¹„ìœ¨": "ë™ì¼ ì—…ì¢… ë‚´ ë§¤ì¶œ ê¸ˆì•¡ ë¹„ìœ¨",
        "ë™ì¼ ì—…ì¢… ë§¤ì¶œ ê¸ˆì•¡ ë¹„ìœ¨": "ë™ì¼ ì—…ì¢… ë‚´ ë§¤ì¶œ ê¸ˆì•¡ ë¹„ìœ¨",
        "ë™ì¼ ì—…ì¢… ë§¤ì¶œê±´ìˆ˜ ë¹„ìœ¨": "ë™ì¼ ì—…ì¢… ë‚´ ë§¤ì¶œ ê±´ìˆ˜ ë¹„ìœ¨",
        "ë™ì¼ ì—…ì¢… ë§¤ì¶œ ê±´ìˆ˜ ë¹„ìœ¨": "ë™ì¼ ì—…ì¢… ë‚´ ë§¤ì¶œ ê±´ìˆ˜ ë¹„ìœ¨",
        "ë™ì¼ ìƒê¶Œ ë§¤ì¶œ ìˆœìœ„ ë¹„ìœ¨": "ë™ì¼ ìƒê¶Œ ë‚´ ë§¤ì¶œ ìˆœìœ„ ë¹„ìœ¨",
        "ìœ ë‹ˆí¬ ê³ ê° ìˆ˜ êµ¬ê°„": "ìœ ë‹ˆí¬ ê³ ê° ìˆ˜ êµ¬ê°„",  # ì‹¤ì œ ì»¬ëŸ¼ ìˆìœ¼ë©´ ì„œë²„ available_kpisì— ë‚˜ì˜µë‹ˆë‹¤
        "ì·¨ì†Œìœ¨ êµ¬ê°„": "ì·¨ì†Œìœ¨ êµ¬ê°„",
    }
    s = synonyms.get(s, s)
    # ë¶ˆí•„ìš”í•œ ì´ì¤‘ ê³µë°± ì œê±°
    s = re.sub(r"\s+", " ", s)
    return s

def _map_kpis_to_available(requested: list[str], available: list[str]) -> list[str]:
    """
    ìš”ì²­ KPI ë¦¬ìŠ¤íŠ¸ë¥¼ available_kpisë¡œ ë§¤í•‘.
    - 1ì°¨: ì •ê·œí™” í›„ ì™„ì „ì¼ì¹˜
    - 2ì°¨: ë¶€ë¶„ í¬í•¨(ì–‘ë°©í–¥)
    - 3ì°¨: ìœ ì‚¬ë„ ë§¤ì¹­(difflib)
    """
    if not requested:
        return []
    req_norm = [_normalize_kpi_name(k) for k in requested if k]
    avail_norm = [re.sub(r"\s+", " ", str(a).strip()) for a in available]

    chosen = []
    def pick(candidate: str):
        if candidate and candidate not in chosen:
            chosen.append(candidate)

    # 1) ì™„ì „ ì¼ì¹˜
    for r in req_norm:
        for a in avail_norm:
            if r == a:
                pick(a)

    # 2) ë¶€ë¶„ í¬í•¨ (r in a ë˜ëŠ” a in r)
    for r in req_norm:
        if any(r == c for c in chosen):
            continue
        hits = [a for a in avail_norm if r in a or a in r]
        if hits:
            pick(hits[0])

    # 3) ìœ ì‚¬ë„ ê¸°ë°˜
    for r in req_norm:
        if any(r == c or r in c or c in r for c in chosen):
            continue
        near = difflib.get_close_matches(r, avail_norm, n=1, cutoff=0.6)
        if near:
            pick(near[0])

    return chosen

def render_timeseries(exploration: dict, merchant_id: str | None = None):
    """ì‹œê³„ì—´ í‘œ ì „ì²´ + ìµœê·¼ Nê°œì›” ìš”ì•½ì„ ë³´ì—¬ì£¼ëŠ” ê³µìš© ì„¹ì…˜."""
    ts = exploration.get("time_series_analysis_data") or []
    if not ts:
        st.info("ì‹œê³„ì—´ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    df = pd.DataFrame(ts)

    # ê¸°ì¤€ë…„ì›” ì»¬ëŸ¼ì´ ë¬¸ìì—´/íƒ€ì… í˜¼ì¬ì¼ ìˆ˜ ìˆìœ¼ë‹ˆ ì•ˆì „ ì •ë ¬
    if "ê¸°ì¤€ë…„ì›”" in df.columns:
        try:
            df["ê¸°ì¤€ë…„ì›”"] = pd.to_datetime(df["ê¸°ì¤€ë…„ì›”"])
        except Exception:
            pass
        df = df.sort_values("ê¸°ì¤€ë…„ì›”")

    st.subheader("â‘¡ ì‹œê³„ì—´ ì „ì²´(2023~2024)")
    st.dataframe(df, width="stretch")  # ìµœì‹  streamlit ê¶Œì¥ íŒŒë¼ë¯¸í„°

    # ìµœê·¼ Nê°œì›”ë§Œ ìš”ì•½
    if len(df) > 12:
        slider_key = f"ts_slider_{merchant_id or 'na'}"
        n = st.slider("ìµœê·¼ Nê°œì›”ë§Œ ë³´ê¸°", min_value=6, max_value=min(36, len(df)), value=12, key=slider_key)
        st.subheader(f"â‘¡-1 ìµœê·¼ {n}ê°œì›”")
        st.dataframe(df.tail(n), width="stretch")


# --- í•œ ë²ˆì— ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ (í›„ë³´ê°€ 1ê°œ ë˜ëŠ” ì´ë¯¸ ì„ íƒëœ ê²½ìš°) ---
def run_full_pipeline(user_text: str, merchant_id: str | None = None):
    agent = st.session_state.agent

    # 1) ë³€í™˜
    trans = agent.transform(user_text)
    st.session_state.transformation = trans

    # 2) í›„ë³´ ê²€ìƒ‰(merchant_id ë¯¸ì§€ì •ì´ë©´)
    if merchant_id is None:
        target = (trans or {}).get("target") or user_text
        resp = mcp_call("search_merchant", {"store_name": target})
        st.write("ğŸ” MCP search_merchant:", resp)

        if "error" in resp:
            ai_out = f"ê°€ë§¹ì  ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {resp['error']}"
            st.session_state.messages.append(AIMessage(content=ai_out))
            with st.chat_message("assistant"):
                st.error(ai_out)
            return

        elif resp.get("status") == "clarification_needed":
            st.session_state.candidates = resp.get("candidates", [])
            st.session_state.awaiting_candidate = True
            # ì±„íŒ… ë¦¬ìŠ¤íŠ¸ë¥¼ ì¶”ê°€ë¡œ ì“°ì§€ ì•ŠìŒ (ì¤‘ë³µ ë°©ì§€)
            return


        elif resp.get("status") == "single_candidate":
            merchant_id = resp["candidate"]["ê°€ë§¹ì êµ¬ë¶„ë²ˆí˜¸"]
        else:
            st.session_state.messages.append(AIMessage(content="ê²€ìƒ‰ ì‹¤íŒ¨ ë˜ëŠ” ì•Œ ìˆ˜ ì—†ëŠ” ìƒíƒœì…ë‹ˆë‹¤."))
            with st.chat_message("assistant"):
                st.error("ê²€ìƒ‰ ì‹¤íŒ¨ ë˜ëŠ” ì•Œ ìˆ˜ ì—†ëŠ” ìƒíƒœì…ë‹ˆë‹¤.")
            return

    # 3) ì‹œê³„ì—´ ì¡°íšŒ
    ts_resp = mcp_call("get_store_timeseries", {"merchant_id": str(merchant_id)})
    st.write("ğŸ“ˆ get_store_timeseries:", ts_resp)
    if ts_resp.get("status") != "success":
        ai_out = ts_resp.get("message", "ì‹œê³„ì—´ ì¡°íšŒ ì‹¤íŒ¨")
        st.session_state.messages.append(AIMessage(content=ai_out))
        with st.chat_message("assistant"):
            st.error(ai_out)
        return

    data = ts_resp["data"]
    exploration = {
        "store_identity": data.get("store_identity"),
        "time_series_analysis_data": data.get("time_series_data"),
    }
    st.session_state.exploration = exploration
    # â¬‡ï¸ ì—ì´ì „íŠ¸ ì»¨í…ìŠ¤íŠ¸ì—ë„ ì €ì¥ (generate_reportê°€ _compact_contextì—ì„œ ì½ìŠµë‹ˆë‹¤)
    st.session_state.agent.context["exploration"] = exploration
    st.session_state.selected_merchant_id = merchant_id
    render_timeseries(exploration, merchant_id=merchant_id)

    # 4) ë¬¸ì œ ì •ì˜
    pd_out = agent.define_problem(exploration, st.session_state.transformation)
    # 5) ì „ëµ ì œì•ˆ
    st_out = agent.propose_strategy(pd_out)

    # 6) KPI ìë™ ì°¨íŠ¸ ìƒì„± (ë²„íŠ¼ ì—†ì´ ìë™)
    kpis_from_llm: List[str] = []
    if isinstance(pd_out, dict):
        kpis_from_llm = pd_out.get("kpis") or []
    chart_b64 = None
    used_kpis_shown = None

    if merchant_id and kpis_from_llm:
        # 1ì°¨: ê·¸ëŒ€ë¡œ ì‹œë„
        chart_resp = mcp_call(
            "render_kpi_chart",
            {
                "merchant_id": str(merchant_id),
                "kpi_keys": kpis_from_llm,
                "title": f"KPI Trend â€“ {exploration['store_identity'].get('name')}",
                "normalize_0_1": False,
            },
        )
        st.write("ğŸ–¼ï¸ render_kpi_chart (1st):", chart_resp)

        # ì‹¤íŒ¨ ì‹œ: available_kpis ë°›ì•„ì„œ ë§¤í•‘ í›„ 2ì°¨ ì‹œë„
        if chart_resp.get("status") != "success":
            avail = chart_resp.get("available_kpis", []) or []
            mapped = _map_kpis_to_available(kpis_from_llm, avail)
            # ë„ˆë¬´ ë§ìœ¼ë©´ 3~5ê°œ ì •ë„ë¡œ ì œí•œ(ê°€ë…ì„±)
            mapped = mapped[:5]
            if mapped:
                chart_resp = mcp_call(
                    "render_kpi_chart",
                    {
                        "merchant_id": str(merchant_id),
                        "kpi_keys": mapped,
                        "title": f"KPI Trend â€“ {exploration['store_identity'].get('name')}",
                        "normalize_0_1": False,
                    },
                )
                st.write("ğŸ–¼ï¸ render_kpi_chart (2nd, mapped):", chart_resp)

        if chart_resp.get("status") == "success":
            chart_b64 = (chart_resp.get("image") or {}).get("base64")
            used_kpis_shown = chart_resp.get("used_kpis", [])
            st.session_state.last_chart_b64 = chart_b64

    # 7) ìµœì¢… ë³´ê³ ì„œ
    report_md = agent.generate_report()

    if not report_md or "ë³´ê³ ì„œ ìƒì„±ì— ì‹¤íŒ¨" in report_md:
        si = exploration.get("store_identity", {})
        fallback = [
            f"# {si.get('name','ê°€ë§¹ì ')} ì»¨ì„¤íŒ… ìš”ì•½",
            "## ë¬¸ì œ ì •ì˜",
            "```json",
            json.dumps(pd_out, ensure_ascii=False, indent=2),
            "```",
            "## ì „ëµ ì œì•ˆ",
            "```json",
            json.dumps(st_out, ensure_ascii=False, indent=2),
            "```",
            "## ê¸°ëŒ€ íš¨ê³¼",
            "- ë§¤ì¶œ/ë°©ë¬¸ ì§€í‘œ ê°œì„  ê¸°ëŒ€",
            "- ì‹ ê·œ ìœ ì… ë° ì¬ë°©ë¬¸ í™•ëŒ€",
            "- ê³ ê°ì¸µ ì„¸ë¶„í™” ê¸°ë°˜ ë©”ì‹œì§€ ì •êµí™”",
        ]
        report_md = "\n".join(fallback)

    # --- ì‘ë‹µì„ "ì±„íŒ… ë©”ì‹œì§€"ë¡œ êµ¬ì„±í•´ íˆìŠ¤í† ë¦¬ì— ë‚¨ê¹€ ---
    parts = []
    si = exploration["store_identity"] or {}
    parts.append(f"**ê°€ë§¹ì :** {si.get('name')} / {si.get('industry')} / {si.get('commercial_area')}")
    parts.append("### 1) ë¬¸ì œ ì •ì˜")
    parts.append("```json\n" + json.dumps(pd_out, ensure_ascii=False, indent=2) + "\n```")
    parts.append("### 2) ì „ëµ ì œì•ˆ")
    parts.append("```json\n" + json.dumps(st_out, ensure_ascii=False, indent=2) + "\n```")
    if kpis_from_llm:
        parts.append("**ìë™ ì„ íƒëœ KPI:** " + ", ".join(kpis_from_llm))
    parts.append("### 3) ìµœì¢… ë³´ê³ ì„œ (ìš”ì•½ ë³´ê¸°)")
    # ë³´ê³ ì„œëŠ” ê¸¸ ìˆ˜ ìˆìœ¼ë‹ˆ ì¼ë¶€ë§Œ
    parts.append(report_md[:1800] + ("..." if len(report_md) > 1800 else ""))
    ai_reply = "\n\n".join(parts)

    st.session_state.messages.append(AIMessage(content=ai_reply))
    with st.chat_message("assistant"):
        st.markdown(ai_reply)
        if chart_b64:
            st.image(base64.b64decode(chart_b64), width="stretch")
            st.caption("ìë™ ìƒì„± KPI ì¶”ì„¸ ì°¨íŠ¸")
            if used_kpis_shown:
                st.caption("ì‚¬ìš©ëœ KPI: " + ", ".join(map(str, used_kpis_shown)))

# --- ì…ë ¥ì°½ ---
user_query = st.chat_input("ê°€ë§¹ì  ì´ë¦„ì´ë‚˜ ê³ ë¯¼ì„ ì…ë ¥í•˜ì„¸ìš”.")
if user_query:
    st.session_state.user_query = user_query
    st.session_state.messages.append(HumanMessage(content=user_query))
    with st.chat_message("user"):
        st.write(user_query)

    # ì´ë¯¸ í›„ë³´ ì„ íƒ ë‹¨ê³„ë©´ ìƒˆ ê²€ìƒ‰ì€ ê±´ë„ˆë›°ê³ , ì•„ë˜ í›„ë³´ UIê°€ ë Œë”ë˜ë„ë¡ ë‘¡ë‹ˆë‹¤.
    if not (st.session_state.awaiting_candidate and st.session_state.candidates):
        # ì¼ë°˜ ê²€ìƒ‰ â†’ ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ (í•„ìš”í•˜ë©´ ì´ ì•ˆì—ì„œ awaiting_candidate=Trueë¡œ ì „í™˜ë¨)
        run_full_pipeline(user_query, merchant_id=None)

# --- í›„ë³´ ì„ íƒ UI (ì—¬ê¸° í•œ ê³³ì—ì„œë§Œ ì¶œë ¥) ---
if st.session_state.awaiting_candidate and st.session_state.candidates:
    st.info("ì´ë¦„ì´ ìœ ì‚¬í•œ ê°€ë§¹ì ì´ ì—¬ëŸ¬ ê°œì…ë‹ˆë‹¤. ì•„ë˜ì—ì„œ í•˜ë‚˜ë¥¼ ì„ íƒí•˜ì„¸ìš”.")

    cands = st.session_state.candidates
    idx = st.radio(
        "ê°€ë§¹ì ì„ ì„ íƒí•˜ì„¸ìš”",
        options=list(range(len(cands))),
        format_func=lambda i: _fmt_cand_with_id(cands[i]),
        key="cand_radio",
    )

    col1, col2 = st.columns(2)
    with col1:
        if st.button("ì„ íƒ í™•ì •", key="cand_confirm"):
            sel = cands[idx]
            picked_id = str(sel.get("ê°€ë§¹ì êµ¬ë¶„ë²ˆí˜¸"))
            st.session_state.awaiting_candidate = False
            # ì„ íƒ ì¦‰ì‹œ ì „ì²´ íŒŒì´í”„ë¼ì¸ ì¬ê°œ (ì‹œê³„ì—´ í‘œ â†’ ë¬¸ì œì •ì˜/ì „ëµ/KPI/ë³´ê³ ì„œ)
            run_full_pipeline(st.session_state.user_query or sel.get("ê°€ë§¹ì ëª…", ""), merchant_id=picked_id)

    with col2:
        if st.button("ì„ íƒ ì·¨ì†Œ", key="cand_cancel"):
            st.session_state.awaiting_candidate = False
            st.session_state.candidates = []
            st.session_state.exploration = None